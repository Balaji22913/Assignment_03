{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a609b6c4-3684-44e4-a54a-90aba1fbc9dc",
   "metadata": {},
   "source": [
    "Q1. What is Ridge Regression, and how does it differ from ordinary least squares regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908a1044-4569-4b21-9c1f-160f3548b4d5",
   "metadata": {},
   "source": [
    "Ridge regression is a term used to refer to a linear regression model whose coefficients are estimated not by ordinary least squares (OLS), but by an estimator, called ridge estimator, that, albeit biased, has lower variance than the OLS estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19176793-3330-400a-926c-dee5b2774c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d26e001d-bbf3-45ff-bc72-aa5a64feb0a0",
   "metadata": {},
   "source": [
    "Q2. What are the assumptions of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3183549e-c9e7-49d3-8e70-6e983f98fa65",
   "metadata": {},
   "source": [
    "The assumptions of ridge regression are the same as that of linear regression: linearity, constant variance, and independence. However, as ridge regression does not provide confidence limits, the distribution of errors to be normal need not be assumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b20cd2-6a36-46c0-9956-46dc84759b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18a5de41-a491-415e-a43d-36841003ea8c",
   "metadata": {},
   "source": [
    "Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b2fee2-1cdc-4d1e-8ae9-43a6660a0d3e",
   "metadata": {},
   "source": [
    "Selecting a good value for λ is critical. When λ=0, the penalty term has no effect, and ridge regression will produce the classical least square coefficients. However, as λ increases to infinite, the impact of the shrinkage penalty grows, and the ridge regression coefficients will get close zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea27c7-2495-4482-b369-9471a74ea644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cad3775-81a5-4b06-83ca-fe7eb9ebb3d7",
   "metadata": {},
   "source": [
    "Q4. Can Ridge Regression be used for feature selection? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb0bf7f-bf4f-43c1-9143-32ebdbbc53bc",
   "metadata": {},
   "source": [
    " Ridge regression can help us in feature selection to find out the important features required for modelling purposes. It is done by Lasso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502e345b-0c98-4213-9833-50d68e31149f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4519446-2c78-44f9-a9c5-f0573465b373",
   "metadata": {},
   "source": [
    "Q5. How does the Ridge Regression model perform in the presence of multicollinearity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91694a8-fb60-4dd4-a2e5-23f6d39cd95a",
   "metadata": {},
   "source": [
    " Ridge regression aims at reducing the standard error by adding some bias in the estimates of the regression. The reduction of the standard error in regression estimates significantly increases the reliability of the estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581eaad-691e-4233-96bd-160fc61da00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffecdb7d-f83f-45dd-ac65-880c5a906f5b",
   "metadata": {},
   "source": [
    "Q6. Can Ridge Regression handle both categorical and continuous independent variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98730387-5385-4620-ab54-96b0ab9f777e",
   "metadata": {},
   "source": [
    "Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28f8d5-7e64-4d35-ae65-fb39baa42458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "daa43da5-4099-4ce9-996e-f5e8ce132c5d",
   "metadata": {},
   "source": [
    "Q7. How do you interpret the coefficients of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a2141f-8e44-4756-81bd-08242dc7c3aa",
   "metadata": {},
   "source": [
    "A positive coefficient indicates that as the value of the independent variable increases, the mean of the dependent variable also tends to increase. A negative coefficient suggests that as the independent variable increases, the dependent variable tends to decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a91645-c5b3-4e45-a6d7-7d9d0f21046b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe50096f-580a-450b-9d11-109dd3c68e3f",
   "metadata": {},
   "source": [
    "Q8. Can Ridge Regression be used for time-series data analysis? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13741489-84e1-4058-836b-2b2cadb607b2",
   "metadata": {},
   "source": [
    "The ridge regression technique can be used to predict time-series. Ridge regression (RR) can also solve the multicollinearity problem that exists in linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455038a8-b2ce-4ab4-8307-38b0e47db3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
