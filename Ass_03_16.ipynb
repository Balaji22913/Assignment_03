{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29ffd167-e58c-4bee-8061-2e04a9c5aea3",
   "metadata": {},
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
    "can they be mitigated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d77d4-755f-4e71-b56d-11267a10a147",
   "metadata": {},
   "source": [
    "When accuracy is high in test dataset and low in train dataset, it is called overfitting.    \n",
    "When accuracy is low in test dataset and low in train dataset, it is called underfitting.    \n",
    "\n",
    "When the model memorizes the noise and fits too closely to the training set, the model becomes “overfitted,” and it is unable to generalize well to new data. If a model cannot generalize well to new data, then it will not be able to perform the classification or prediction tasks that it was intended for.           \n",
    "\n",
    "An underfit model results in high prediction errors for both training and test data. An overfit model gives a very low prediction error on training data, but a very high prediction error on test data. Both types of models result in poor accuracy.        \n",
    "\n",
    "We can solve the problem of overfitting by: Increasing the training data by data augmentation      \n",
    "\n",
    "We can solve the problem of underfitting by:Feature selection, Increase the duration of training and Decrease regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01502857-98e7-47ff-ac1c-457175eeb62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdc6fc0c-24e9-4e0d-a75d-bc8c49f1a707",
   "metadata": {},
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4686fc50-38ee-49fb-b939-f6418442c1fd",
   "metadata": {},
   "source": [
    "You can prevent overfitting by diversifying and scaling your training data set or using some other data science strategies, like Data augmentation, Regularization and Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadb693a-fa82-483c-9725-4c4f0f5a7844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8de2913d-436e-4c6a-8955-33efd8f91caa",
   "metadata": {},
   "source": [
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c74ae4-6271-4d10-84fc-532aae1e90cf",
   "metadata": {},
   "source": [
    "Underfitting is a scenario in data science where a data model is unable to capture the relationship between the input and output variables accurately, generating a high error rate on both the training set and unseen data. It occurs when a model is too simple, which can be a result of a model needing more training time, more input features, or less regularization. Like overfitting, when a model is underfitted, it cannot establish the dominant trend within the data, resulting in training errors and poor performance of the model. If a model cannot generalize well to new data, then it cannot be leveraged for classification or prediction tasks. Generalization of a model to new data is ultimately what allows us to use machine learning algorithms every day to make predictions and classify data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4c8e1c-5520-494a-b073-f9f063f1e943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c14bd8a3-83af-4917-a6f1-d0f1519bb6a0",
   "metadata": {},
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "variance, and how do they affect model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae10ac3-db63-4859-a226-e1483dff30a6",
   "metadata": {},
   "source": [
    "In statistics and machine learning, the bias–variance tradeoff is the property of a model that the variance of the parameter estimated across samples can be reduced by increasing the bias in the estimated parameters.            \n",
    "\n",
    "Bias and variance are inversely connected. It is impossible to have an ML model with a low bias and a low variance. When a data engineer modifies the ML algorithm to better fit a given data set, it will lead to low bias—but it will increase variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44078a-15a7-443e-9465-3f752ed7e1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35ff77b4-d3a2-48e0-8626-b59bf338b765",
   "metadata": {},
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "How can you determine whether your model is overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a09b2-8cf4-45ea-9d80-dc48ff60d74f",
   "metadata": {},
   "source": [
    "We can determine whether a predictive model is underfitting or overfitting the training data by looking at the prediction error on the training data and the evaluation data. Your model is underfitting the training data when the model performs poorly on the training data.       \n",
    "\n",
    "We can determine whether a predictive model is underfitting or overfitting the training data by looking at the prediction error on the training data and the evaluation data. Your model is underfitting the training data when the model performs poorly on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ec364-d26c-459d-8d5b-d142bea7c156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c34c79d2-3be8-4ec8-9edd-ed954f03c680",
   "metadata": {},
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "and high variance models, and how do they differ in terms of their performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc087ac-a7e1-4959-a600-d14adc743422",
   "metadata": {},
   "source": [
    "The term \"variance\" refers to the degree of change that may be expected in the estimation of the target function as a result of using multiple sets of training data. The disparity between the values that were predicted and the values that were actually observed is referred to as bias.         \n",
    "\n",
    "Examples of high-bias machine learning algorithms include: Linear Regression, Linear Discriminant Analysis and Logistic Regression.     \n",
    "Examples of high-variance machine learning algorithms include: Decision Trees, k-Nearest Neighbors and Support Vector Machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf3bfee-5fae-4aed-ba43-9380c72efd35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35a3aff6-a06e-470d-8abc-94c2a9380319",
   "metadata": {},
   "source": [
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95acbe15-57a5-4eee-a870-d084585278c2",
   "metadata": {},
   "source": [
    "Regularization refers to techniques that are used to calibrate machine learning models in order to minimize the adjusted loss function and prevent overfitting or underfitting. Using Regularization, we can fit our machine learning model appropriately on a given test set and hence reduce the errors in it.        \n",
    "\n",
    "Regularization works by adding a penalty or complexity term or shrinkage term with Residual Sum of Squares (RSS) to the complex model.L1 and L2 are the most common types of regularization. These update the general cost function by adding another term known as the regularization term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1099683-ff4e-41f0-8e40-2531fe149e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
